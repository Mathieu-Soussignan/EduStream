import textwrap

def load_summary_model():
    """
    Charge dynamiquement le pipeline de summarization pour Ã©viter les conflits 
    avec le watcher Streamlit au dÃ©marrage.
    """
    print("ğŸš€ Chargement du modÃ¨le Hugging Face...")
    from transformers import pipeline
    return pipeline("summarization", model="sshleifer/distilbart-cnn-12-6")


def split_text(text, max_chunk_length=1000):
    """
    DÃ©coupe un long texte en morceaux plus petits, basÃ©s sur les sauts de ligne ou les mots.

    Args:
        text (str): Le texte Ã  dÃ©couper.
        max_chunk_length (int): Longueur max (en caractÃ¨res) de chaque chunk.

    Returns:
        list[str]: Liste de morceaux de texte.
    """
    paragraphs = text.split("\n")
    chunks = []
    current_chunk = ""

    for paragraph in paragraphs:
        if len(current_chunk) + len(paragraph) + 1 <= max_chunk_length:
            current_chunk += paragraph + "\n"
        else:
            if current_chunk:
                chunks.append(current_chunk.strip())
            current_chunk = paragraph + "\n"

    if current_chunk:
        chunks.append(current_chunk.strip())

    return chunks


def summarize(text, model, max_length=120, min_length=30, max_chunk_length=1000):
    """
    GÃ©nÃ¨re un rÃ©sumÃ© Ã  partir du texte donnÃ©, mÃªme s'il est long (en le dÃ©coupant si nÃ©cessaire).

    Args:
        text (str): Le texte Ã  rÃ©sumer.
        model (pipeline): Le pipeline de summarization prÃ©chargÃ©.
        max_length (int): Longueur maximale du rÃ©sumÃ©.
        min_length (int): Longueur minimale du rÃ©sumÃ©.
        max_chunk_length (int): Longueur max des morceaux en cas de dÃ©coupage.

    Returns:
        str: Le rÃ©sumÃ© gÃ©nÃ©rÃ©.
    """
    cleaned_text = text.strip()
    print(f"ğŸ§ª Longueur du texte : {len(cleaned_text)} caractÃ¨res")

    if not cleaned_text or len(cleaned_text) < 50:
        print("âŒ Texte trop court pour le rÃ©sumÃ©.")
        return "â›” Le texte est trop court pour Ãªtre rÃ©sumÃ©."

    print("ğŸ§© VÃ©rification de la longueur...")
    if len(cleaned_text) > max_chunk_length:
        print("âœ‚ï¸ Texte trop long : dÃ©coupage en morceaux...")
        chunks = split_text(cleaned_text, max_chunk_length=max_chunk_length)
        print(f"ğŸ“¦ {len(chunks)} morceaux Ã  rÃ©sumer")
        summaries = []
        for i, chunk in enumerate(chunks, 1):
            print(f"ğŸ”¹ RÃ©sumÃ© du morceau {i}/{len(chunks)}...")
            summary = model(chunk, max_length=max_length, min_length=min_length, do_sample=False)
            summaries.append(summary[0]['summary_text'])
        print("âœ… Tous les rÃ©sumÃ©s partiels gÃ©nÃ©rÃ©s.")
        return "\n\n".join(summaries)
    else:
        print("âš™ï¸ Appel du pipeline de summarization...")
        result = model(cleaned_text, max_length=max_length, min_length=min_length, do_sample=False)
        print("âœ… RÃ©sumÃ© gÃ©nÃ©rÃ© !")
        return result[0]['summary_text']