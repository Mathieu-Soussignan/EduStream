import textwrap

def load_summary_model():
    """
    Mod√®le fran√ßais T5 fine-tun√© pour le r√©sum√© (CNN/DM FR).
    Meilleure stabilit√© et pertinence sur des contenus p√©dagogiques.
    """
    from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline

    model_name = "plguillou/t5-base-fr-sum-cnndm"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

    return pipeline("summarization", model=model, tokenizer=tokenizer)


def split_text(text, max_chunk_length=1000):
    """
    D√©coupe un long texte en morceaux plus petits, bas√©s sur les sauts de ligne ou les mots.

    Args:
        text (str): Le texte √† d√©couper.
        max_chunk_length (int): Longueur max (en caract√®res) de chaque chunk.

    Returns:
        list[str]: Liste de morceaux de texte.
    """
    paragraphs = text.split("\n")
    chunks = []
    current_chunk = ""

    for paragraph in paragraphs:
        if len(current_chunk) + len(paragraph) + 1 <= max_chunk_length:
            current_chunk += paragraph + "\n"
        else:
            if current_chunk:
                chunks.append(current_chunk.strip())
            current_chunk = paragraph + "\n"

    if current_chunk:
        chunks.append(current_chunk.strip())

    return chunks


def summarize(text, model, max_length=120, min_length=30, max_chunk_length=1000):
    """
    G√©n√®re un r√©sum√© √† partir du texte donn√©, m√™me s'il est long (en le d√©coupant si n√©cessaire).

    Args:
        text (str): Le texte √† r√©sumer.
        model (pipeline): Le pipeline de summarization pr√©charg√©.
        max_length (int): Longueur maximale du r√©sum√©.
        min_length (int): Longueur minimale du r√©sum√©.
        max_chunk_length (int): Longueur max des morceaux en cas de d√©coupage.

    Returns:
        str: Le r√©sum√© g√©n√©r√©.
    """
    cleaned_text = text.strip()
    print(f"üß™ Longueur du texte : {len(cleaned_text)} caract√®res")

    if not cleaned_text or len(cleaned_text) < 50:
        print("‚ùå Texte trop court pour le r√©sum√©.")
        return "‚õî Le texte est trop court pour √™tre r√©sum√©."

    print("üß© V√©rification de la longueur...")
    if len(cleaned_text) > max_chunk_length:
        print("‚úÇÔ∏è Texte trop long : d√©coupage en morceaux...")
        chunks = split_text(cleaned_text, max_chunk_length=max_chunk_length)
        print(f"üì¶ {len(chunks)} morceaux √† r√©sumer")
        summaries = []
        for i, chunk in enumerate(chunks, 1):
            print(f"üîπ R√©sum√© du morceau {i}/{len(chunks)}...")
            summary = model(chunk, max_length=max_length, min_length=min_length, do_sample=False)
            summaries.append(summary[0]['summary_text'])
        print("‚úÖ Tous les r√©sum√©s partiels g√©n√©r√©s.")
        return "\n\n".join(summaries)
    else:
        print("‚öôÔ∏è Appel du pipeline de summarization...")
        result = model(cleaned_text, max_length=max_length, min_length=min_length, do_sample=False)
        print("‚úÖ R√©sum√© g√©n√©r√© !")
        return result[0]['summary_text']